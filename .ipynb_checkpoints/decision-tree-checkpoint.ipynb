{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bd8f30e",
   "metadata": {},
   "source": [
    "# Coding decision tree\n",
    "\n",
    "In decision trees, the key is to find an efficient way to split the data based on its features. There are two popular ways to do that:\n",
    "\n",
    "1) Entropy change. The criterion for entropy is **Shannon's entropy** formula: $\\displaystyle -\\sum_{n=1}^{N}p_n log_{2}(p_n)$, where $N$ is the number of all possible states the system could be found in, and $p_n$ is the probability of finding the system in n-th state. For example, in binary classification tasks, the system could be found in only 2 possible states - when target variable is equal to 0 or 1. If we have [1,1,0,0,1,0,1,0,1,1,0,1], the $p_n$ for n=0 is $\\frac{5}{12}$, and for n=1 is $\\frac{7}{12}$.\n",
    "\n",
    "Entropy change is called an **information gain**. $IG = E_0 - (-\\sum_{n=1}^{N}p_n log_{2}(p_n))$, where $E_0$ is the initial entropy (before current split).\n",
    "\n",
    "Higher entropy, as we know from physics course termodynamics, correlates with higher degree of chaos. Since we want to differentiate between classes, we need to minimize the entropy, or maximize the infrmation gain.\n",
    "\n",
    "2) **Gini index**, also known as Gini impurity. It has the same variables but different formula: $G = 1 - \\sum_{n=1}^{N}p_n^2$, where $p_n$ is again the probability of finding system in n-th state given $N$ is the number of all possible system states.\n",
    "\n",
    "$\\displaystyle \\Delta Gini = Gini_{parent} - (Gini_{left}\\frac{n_{left}}{n_{right} + n_{left}} + Gini_{right}\\frac{n_{right}}{n_{right} + n_{left}})$\n",
    "\n",
    "The formula above shows that $\\displaystyle \\Delta Gini$ is calculated using *weighted* gini indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b8a6d0",
   "metadata": {},
   "source": [
    "### Best split\n",
    "\n",
    "To find the best split among numeric columns, *means of neighbors* are used.\n",
    "\n",
    "$[1,2,5,6,10] -> [1.5,3.5,5.5,8]$\n",
    "\n",
    "It helps to iterate over every possible split.\n",
    "\n",
    "Pseudo code:\n",
    "\n",
    "    for feature in features:\n",
    "        for mean in [means of neighbors]:\n",
    "            find gini impurity\n",
    "            find gini gain\n",
    "            \n",
    "    return (best_split, best_feature) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7229495",
   "metadata": {},
   "source": [
    "### Tree results\n",
    "\n",
    "The main takeaways of the algorithm will be displayed in `print_tree()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e720402",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root\n",
      "   | Gini impurity of the node: 0.5\n",
      "   | Class distribution in the node: {1: 165, 0: 138}\n",
      "   | Predicted class: 1\n",
      "|-------- Split rule: age < 54.5\n",
      "           | Gini impurity of the node: 0.42\n",
      "           | Class distribution in the node: {1: 100, 0: 44}\n",
      "           | Predicted class: 1\n",
      "|---------------- Split rule: age < 42.5\n",
      "                   | Gini impurity of the node: 0.34\n",
      "                   | Class distribution in the node: {1: 29, 0: 8}\n",
      "                   | Predicted class: 1\n",
      "|------------------------ Split rule: age < 40.5\n",
      "                           | Gini impurity of the node: 0.43\n",
      "                           | Class distribution in the node: {1: 13, 0: 6}\n",
      "                           | Predicted class: 1\n",
      "|-------------------------------- Split rule: age < 39.5\n",
      "                                   | Gini impurity of the node: 0.38\n",
      "                                   | Class distribution in the node: {1: 12, 0: 4}\n",
      "                                   | Predicted class: 1\n",
      "|---------------------------------------- Split rule: age < 34.5\n",
      "                                           | Gini impurity of the node: 0.0\n",
      "                                           | Class distribution in the node: {1: 3}\n",
      "                                           | Predicted class: 1\n",
      "|---------------------------------------- Split rule: age >= 34.5 \n",
      "                                           | Gini impurity of the node: 0.43\n",
      "                                           | Class distribution in the node: {1: 9, 0: 4}\n",
      "                                           | Predicted class: 1\n",
      "|-------------------------------- Split rule: age >= 39.5 \n",
      "                                   | Gini impurity of the node: 0.44\n",
      "                                   | Class distribution in the node: {1: 1, 0: 2}\n",
      "                                   | Predicted class: 0\n",
      "|------------------------ Split rule: age >= 40.5 \n",
      "                           | Gini impurity of the node: 0.2\n",
      "                           | Class distribution in the node: {1: 16, 0: 2}\n",
      "                           | Predicted class: 1\n",
      "|-------------------------------- Split rule: age < 41.5\n",
      "                                   | Gini impurity of the node: 0.18\n",
      "                                   | Class distribution in the node: {1: 9, 0: 1}\n",
      "                                   | Predicted class: 1\n",
      "|-------------------------------- Split rule: age >= 41.5 \n",
      "                                   | Gini impurity of the node: 0.22\n",
      "                                   | Class distribution in the node: {1: 7, 0: 1}\n",
      "                                   | Predicted class: 1\n",
      "|---------------- Split rule: age >= 42.5 \n",
      "                   | Gini impurity of the node: 0.45\n",
      "                   | Class distribution in the node: {1: 71, 0: 36}\n",
      "                   | Predicted class: 1\n",
      "|------------------------ Split rule: age < 50.5\n",
      "                           | Gini impurity of the node: 0.46\n",
      "                           | Class distribution in the node: {1: 37, 0: 21}\n",
      "                           | Predicted class: 1\n",
      "|-------------------------------- Split rule: age < 45.5\n",
      "                                   | Gini impurity of the node: 0.42\n",
      "                                   | Class distribution in the node: {1: 19, 0: 8}\n",
      "                                   | Predicted class: 1\n",
      "|---------------------------------------- Split rule: age < 43.5\n",
      "                                           | Gini impurity of the node: 0.47\n",
      "                                           | Class distribution in the node: {1: 5, 0: 3}\n",
      "                                           | Predicted class: 1\n",
      "|---------------------------------------- Split rule: age >= 43.5 \n",
      "                                           | Gini impurity of the node: 0.39\n",
      "                                           | Class distribution in the node: {1: 14, 0: 5}\n",
      "                                           | Predicted class: 1\n",
      "|-------------------------------- Split rule: age >= 45.5 \n",
      "                                   | Gini impurity of the node: 0.49\n",
      "                                   | Class distribution in the node: {1: 18, 0: 13}\n",
      "                                   | Predicted class: 1\n",
      "|---------------------------------------- Split rule: age < 46.5\n",
      "                                           | Gini impurity of the node: 0.49\n",
      "                                           | Class distribution in the node: {1: 4, 0: 3}\n",
      "                                           | Predicted class: 1\n",
      "|---------------------------------------- Split rule: age >= 46.5 \n",
      "                                           | Gini impurity of the node: 0.49\n",
      "                                           | Class distribution in the node: {1: 14, 0: 10}\n",
      "                                           | Predicted class: 1\n",
      "|------------------------ Split rule: age >= 50.5 \n",
      "                           | Gini impurity of the node: 0.42\n",
      "                           | Class distribution in the node: {1: 34, 0: 15}\n",
      "                           | Predicted class: 1\n",
      "|-------------------------------- Split rule: age < 53.5\n",
      "                                   | Gini impurity of the node: 0.4\n",
      "                                   | Class distribution in the node: {1: 24, 0: 9}\n",
      "                                   | Predicted class: 1\n",
      "|---------------------------------------- Split rule: age < 51.5\n",
      "                                           | Gini impurity of the node: 0.38\n",
      "                                           | Class distribution in the node: {1: 9, 0: 3}\n",
      "                                           | Predicted class: 1\n",
      "|---------------------------------------- Split rule: age >= 51.5 \n",
      "                                           | Gini impurity of the node: 0.41\n",
      "                                           | Class distribution in the node: {1: 15, 0: 6}\n",
      "                                           | Predicted class: 1\n",
      "|-------------------------------- Split rule: age >= 53.5 \n",
      "                                   | Gini impurity of the node: 0.47\n",
      "                                   | Class distribution in the node: {1: 10, 0: 6}\n",
      "                                   | Predicted class: 1\n",
      "|-------- Split rule: age >= 54.5 \n",
      "           | Gini impurity of the node: 0.48\n",
      "           | Class distribution in the node: {1: 65, 0: 94}\n",
      "           | Predicted class: 0\n",
      "|---------------- Split rule: age < 70.5\n",
      "                   | Gini impurity of the node: 0.48\n",
      "                   | Class distribution in the node: {1: 60, 0: 93}\n",
      "                   | Predicted class: 0\n",
      "|------------------------ Split rule: age < 63.5\n",
      "                           | Gini impurity of the node: 0.46\n",
      "                           | Class distribution in the node: {1: 38, 0: 70}\n",
      "                           | Predicted class: 0\n",
      "|-------------------------------- Split rule: age < 59.5\n",
      "                                   | Gini impurity of the node: 0.48\n",
      "                                   | Class distribution in the node: {1: 27, 0: 42}\n",
      "                                   | Predicted class: 0\n",
      "|---------------------------------------- Split rule: age < 57.5\n",
      "                                           | Gini impurity of the node: 0.49\n",
      "                                           | Class distribution in the node: {1: 15, 0: 21}\n",
      "                                           | Predicted class: 0\n",
      "|---------------------------------------- Split rule: age >= 57.5 \n",
      "                                           | Gini impurity of the node: 0.46\n",
      "                                           | Class distribution in the node: {1: 12, 0: 21}\n",
      "                                           | Predicted class: 0\n",
      "|-------------------------------- Split rule: age >= 59.5 \n",
      "                                   | Gini impurity of the node: 0.4\n",
      "                                   | Class distribution in the node: {1: 11, 0: 28}\n",
      "                                   | Predicted class: 0\n",
      "|---------------------------------------- Split rule: age < 61.5\n",
      "                                           | Gini impurity of the node: 0.33\n",
      "                                           | Class distribution in the node: {1: 4, 0: 15}\n",
      "                                           | Predicted class: 0\n",
      "|---------------------------------------- Split rule: age >= 61.5 \n",
      "                                           | Gini impurity of the node: 0.45\n",
      "                                           | Class distribution in the node: {1: 7, 0: 13}\n",
      "                                           | Predicted class: 0\n",
      "|------------------------ Split rule: age >= 63.5 \n",
      "                           | Gini impurity of the node: 0.5\n",
      "                           | Class distribution in the node: {1: 22, 0: 23}\n",
      "                           | Predicted class: 0\n",
      "|-------------------------------- Split rule: age < 66.5\n",
      "                                   | Gini impurity of the node: 0.49\n",
      "                                   | Class distribution in the node: {1: 14, 0: 11}\n",
      "                                   | Predicted class: 1\n",
      "|---------------------------------------- Split rule: age < 64.5\n",
      "                                           | Gini impurity of the node: 0.48\n",
      "                                           | Class distribution in the node: {1: 6, 0: 4}\n",
      "                                           | Predicted class: 1\n",
      "|---------------------------------------- Split rule: age >= 64.5 \n",
      "                                           | Gini impurity of the node: 0.5\n",
      "                                           | Class distribution in the node: {1: 8, 0: 7}\n",
      "                                           | Predicted class: 1\n",
      "|-------------------------------- Split rule: age >= 66.5 \n",
      "                                   | Gini impurity of the node: 0.48\n",
      "                                   | Class distribution in the node: {1: 8, 0: 12}\n",
      "                                   | Predicted class: 0\n",
      "|---------------------------------------- Split rule: age < 69.5\n",
      "                                           | Gini impurity of the node: 0.49\n",
      "                                           | Class distribution in the node: {1: 7, 0: 9}\n",
      "                                           | Predicted class: 0\n",
      "|---------------------------------------- Split rule: age >= 69.5 \n",
      "                                           | Gini impurity of the node: 0.38\n",
      "                                           | Class distribution in the node: {1: 1, 0: 3}\n",
      "                                           | Predicted class: 0\n",
      "|---------------- Split rule: age >= 70.5 \n",
      "                   | Gini impurity of the node: 0.28\n",
      "                   | Class distribution in the node: {1: 5, 0: 1}\n",
      "                   | Predicted class: 1\n",
      "|------------------------ Split rule: age < 76.5\n",
      "                           | Gini impurity of the node: 0.0\n",
      "                           | Class distribution in the node: {1: 5}\n",
      "                           | Predicted class: 1\n",
      "|------------------------ Split rule: age >= 76.5 \n",
      "                           | Gini impurity of the node: 0.0\n",
      "                           | Class distribution in the node: {0: 1}\n",
      "                           | Predicted class: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    Node class for recursive tree growth.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        X: pd.DataFrame,\n",
    "        y: list,\n",
    "        min_samples_split=None,\n",
    "        max_depth=None,\n",
    "        depth=None,\n",
    "        node_type=None,\n",
    "        rule=None\n",
    "    ):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        self.min_samples_split = min_samples_split if min_samples_split else 1\n",
    "        self.max_depth = max_depth if max_depth else 5\n",
    "        \n",
    "        self.depth = depth if depth else 0\n",
    "        \n",
    "        self.features = list(self.X.columns)\n",
    "        \n",
    "        self.node_type = node_type if node_type else 'root'\n",
    "        \n",
    "        self.rule = rule if rule else \"\"\n",
    "        \n",
    "        # Calculating the counts of y in the node\n",
    "        self.counts = Counter(self.y)\n",
    "        \n",
    "        self.GINI_impurity = self.get_gini()\n",
    "        \n",
    "        # Get the most frequent class\n",
    "        f = None\n",
    "        counts_sorted = list(sorted(self.counts.items(), key=lambda item: item[1]))\n",
    "        \n",
    "        if len(counts_sorted) > 0:\n",
    "            f = counts_sorted[-1][0]\n",
    "            \n",
    "        self.f = f\n",
    "        \n",
    "        # Number of samples in the split\n",
    "        self.n = len(y)\n",
    "        \n",
    "        # Initiate right and left nodes as empty nodes\n",
    "        self.right = None\n",
    "        self.left = None\n",
    "        \n",
    "        # Initiate default values for splits\n",
    "        self.best_value = None\n",
    "        self.best_feature = None\n",
    "    \n",
    "    @staticmethod\n",
    "    def gini_impurity(y1_count: int, y2_count: int) -> float:\n",
    "        \"\"\"\n",
    "        Calculates the the gini impurity given the observations of binary class count.\n",
    "        \"\"\"\n",
    "        if type(y1_count) != int:\n",
    "            y1_count = 0\n",
    "        \n",
    "        if type(y2_count) != int:\n",
    "            y2_count = 0\n",
    "        \n",
    "        # Total observations\n",
    "        n = y1_count + y2_count\n",
    "        \n",
    "        # 0 observations dataset is completely pure\n",
    "        if n == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        p1 = y1_count/n\n",
    "        p2 = y2_count/n\n",
    "        \n",
    "        g = 1 - (p1**2 + p2**2)\n",
    "        \n",
    "        return g\n",
    "    \n",
    "    @staticmethod\n",
    "    def ma(x: np.array, window: int) -> np.array:\n",
    "        \"\"\"\n",
    "        Returns the moving average (means of neighbors) of the given list.\n",
    "        \"\"\"\n",
    "        return np.convolve(x, np.ones(window), 'valid')/window\n",
    "    \n",
    "    def get_gini(self):\n",
    "        \"\"\"\n",
    "        Calculates gini impurity of the node.\n",
    "        \"\"\"\n",
    "        y1_count, y2_count = self.counts.get(0,0), self.counts.get(1,0)  # (key, default)\n",
    "        return self.gini_impurity(y1_count, y2_count)\n",
    "    \n",
    "    def best_split(self) -> tuple:\n",
    "        \"\"\"\n",
    "        Calculates best split for the current node given X features and y targets.\n",
    "        \"\"\"\n",
    "        # Create dataset for making splits\n",
    "        df = self.X.copy()\n",
    "        df['y'] = self.y\n",
    "        \n",
    "        # Initial gini index\n",
    "        gini_base = self.get_gini()\n",
    "        \n",
    "        max_gain = 0\n",
    "        \n",
    "        best_value = None\n",
    "        best_feature = None\n",
    "        \n",
    "        for feature in self.features:\n",
    "            Xdf = df.dropna().sort_values(feature)\n",
    "            \n",
    "            # Finding moving average for sorted unique values -> values used for splits\n",
    "            xmeans = self.ma(Xdf[feature].unique(), 2)\n",
    "            \n",
    "            for value in xmeans:\n",
    "                left_count = Counter(Xdf[Xdf[feature]<value]['y'])\n",
    "                right_count = Counter(Xdf[Xdf[feature]>=value]['y'])\n",
    "                \n",
    "                # Getting the y distribution from the Counter object\n",
    "                y0_left, y1_left = left_count.get(0,0), left_count.get(1,0)\n",
    "                y0_right, y1_right = right_count.get(0,0), right_count.get(1,0)\n",
    "                \n",
    "                gini_left = self.gini_impurity(y0_left, y1_left)\n",
    "                gini_right = self.gini_impurity(y0_right, y1_right)\n",
    "                \n",
    "                n_left = y0_left + y1_left\n",
    "                n_right = y0_right + y1_right\n",
    "                \n",
    "                # Calculate the weights for subnodes\n",
    "                w_left = n_left/(n_left + n_right)\n",
    "                w_right = n_right/(n_left + n_right)\n",
    "                \n",
    "                # Calculate weighted gini impurity\n",
    "                gini_weighted = w_left*gini_left + w_right*gini_right\n",
    "                \n",
    "                gini_gain = gini_base - gini_weighted\n",
    "                \n",
    "                # check if this is the best split so far\n",
    "                if gini_gain > max_gain:\n",
    "                    best_feature = feature\n",
    "                    best_value = value\n",
    "                    \n",
    "                    max_gain = gini_gain\n",
    "                \n",
    "            return (best_feature, best_value)\n",
    "        \n",
    "    def grow_tree(self):\n",
    "        \"\"\"\n",
    "        Recursive method to create decision tree.\n",
    "        \"\"\"\n",
    "        # Make df\n",
    "        df = self.X.copy()\n",
    "        df['y'] = self.y\n",
    "\n",
    "        if (self.depth < self.max_depth) and (self.n >= self.min_samples_split):\n",
    "\n",
    "            best_feature, best_value = self.best_split()\n",
    "\n",
    "            if best_feature is not None:\n",
    "                self.best_feature = best_feature\n",
    "                self.best_value = best_value\n",
    "\n",
    "                # Getting the left and right nodes\n",
    "                left_df = df[df[self.best_feature] < self.best_value].copy()\n",
    "                right_df = df[df[self.best_feature] >= self.best_value].copy()\n",
    "\n",
    "                # Creating the left and the right nodes\n",
    "                left = Node(\n",
    "                    X=left_df[self.features],\n",
    "                    y=left_df['y'].values.tolist(),\n",
    "                    depth=self.depth+1,\n",
    "                    max_depth=self.max_depth,\n",
    "                    min_samples_split=self.min_samples_split,\n",
    "                    node_type='left_node',\n",
    "                    rule=f\"{self.best_feature} < {round(self.best_value, 3)}\"\n",
    "                )\n",
    "\n",
    "                self.left = left\n",
    "                self.left.grow_tree()\n",
    "\n",
    "                right = Node(\n",
    "                    X=right_df[self.features],\n",
    "                    y=right_df['y'].values.tolist(),\n",
    "                    depth=self.depth+1,\n",
    "                    max_depth=self.max_depth,\n",
    "                    min_samples_split=self.min_samples_split,\n",
    "                    node_type='right_node',\n",
    "                    rule=f\"{self.best_feature} >= {round(self.best_value, 3)} \"\n",
    "                )\n",
    "\n",
    "                self.right = right\n",
    "                self.right.grow_tree()\n",
    "\n",
    "    def print_info(self, width=4):\n",
    "        \"\"\"\n",
    "        Method to print the information about the tree.\n",
    "        \"\"\"\n",
    "        const = int(self.depth * width ** 1.5)\n",
    "        spaces = const * \"-\"\n",
    "\n",
    "        if self.node_type == \"root\":\n",
    "            print(\"Root\")\n",
    "        else:\n",
    "            print(f\"|{spaces} Split rule: {self.rule}\")\n",
    "        print(f\"{' ' * const}   | Gini impurity of the node: {round(self.GINI_impurity, 2)}\")\n",
    "        print(f\"{' ' * const}   | Class distribution in the node: {dict(self.counts)}\")\n",
    "        print(f\"{' ' * const}   | Predicted class: {self.f}\")\n",
    "\n",
    "    def print_tree(self):\n",
    "        \"\"\"\n",
    "        Prints the whole tree from top to the bottom.\n",
    "        \"\"\"\n",
    "\n",
    "        self.print_info()\n",
    "\n",
    "        if self.left is not None:\n",
    "            self.left.print_tree()\n",
    "\n",
    "        if self.right is not None:\n",
    "            self.right.print_tree()\n",
    "\n",
    "    def predict(self, X: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Batch prediction method.\n",
    "        \"\"\"\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        for _, x in X.iterrows():  # iterates over the DataFrame as (index, Series) pair\n",
    "            values = {}\n",
    "            for feature in self.features:\n",
    "                values.update({feature: x[feature]})\n",
    "\n",
    "            predictions.append(self.predict_obs(values))\n",
    "\n",
    "        return predictions\n",
    "\n",
    "    def predict_obs(self, values: dict) -> int:\n",
    "        \"\"\"\n",
    "        Method to predict a class given a set of features.\n",
    "        \"\"\"\n",
    "\n",
    "        current_node = self\n",
    "        while current_node.depth < current_node.max_depth:\n",
    "            # Going from top to bottom\n",
    "            best_feature = current_node.best_feature\n",
    "            best_value = current_node.best_value\n",
    "\n",
    "            if current_node.n < current_node.min_samples_split:\n",
    "                break\n",
    "            \n",
    "            if (best_feature == None) or (best_value == None):\n",
    "                break\n",
    "            if (values.get(best_feature) < best_value):\n",
    "                if self.left is not None:\n",
    "                    current_node = current_node.left\n",
    "            else:\n",
    "                if self.right is not None:\n",
    "                    current_node = current_node.right\n",
    "\n",
    "        return current_node.f\n",
    "    \n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv('../../Kaggle/heart-disease/heart-disease.csv')\n",
    "    X = df.dropna().drop([\"target\"], axis=1).copy()\n",
    "    y = df['target'].values.tolist()\n",
    "    \n",
    "    clf = Node(X, y)\n",
    "    clf.grow_tree()\n",
    "    \n",
    "    clf.print_tree()\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
